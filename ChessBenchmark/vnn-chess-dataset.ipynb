{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a2f05f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-11T17:10:55.236143Z",
     "iopub.status.busy": "2022-10-11T17:10:55.235698Z",
     "iopub.status.idle": "2022-10-11T17:11:08.592847Z",
     "shell.execute_reply": "2022-10-11T17:11:08.591765Z"
    },
    "papermill": {
     "duration": 13.365268,
     "end_time": "2022-10-11T17:11:08.595419",
     "exception": false,
     "start_time": "2022-10-11T17:10:55.230151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chess in c:\\users\\eshaa\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install chess\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "import chess\n",
    "from tqdm import trange\n",
    "import linecache\n",
    "from random import randint\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6323a7b9",
   "metadata": {
    "papermill": {
     "duration": 0.002276,
     "end_time": "2022-10-11T17:11:08.600538",
     "exception": false,
     "start_time": "2022-10-11T17:11:08.598262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# VNN DECLARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824e62c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T17:11:08.607135Z",
     "iopub.status.busy": "2022-10-11T17:11:08.606615Z",
     "iopub.status.idle": "2022-10-11T17:11:08.625573Z",
     "shell.execute_reply": "2022-10-11T17:11:08.624647Z"
    },
    "papermill": {
     "duration": 0.024521,
     "end_time": "2022-10-11T17:11:08.627477",
     "exception": false,
     "start_time": "2022-10-11T17:11:08.602956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PosEncIndex(nn.Module):\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        length = torch.max(x).item()+1\n",
    "        \n",
    "        pe = torch.zeros((length, self.d_model)).to(self.device)\n",
    "        position = torch.arange(0, length).unsqueeze(1)\n",
    "        div_term = torch.exp((torch.arange(0, self.d_model, 2, dtype=torch.float) *\n",
    "                            -(math.log(10000.0) / self.d_model)))\n",
    "        pe[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "\n",
    "        return pe[x]\n",
    "\n",
    "class VNNBlock (nn.Module):\n",
    "    def __init__(self, d_model, weight_nn, bias_nn) -> None:\n",
    "        super().__init__()\n",
    "        self.weight_nn = weight_nn \n",
    "        self.bias_nn = bias_nn \n",
    "        self.pos_enc = PosEncIndex(d_model)\n",
    "\n",
    "    def weight_propagation (self, x, output_size, extra_out):\n",
    "        input_size = x.size(1)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #* Weight Generation\n",
    "        # Generate the weight vector\n",
    "        argument_one = torch.arange(input_size)\n",
    "        argument_two = torch.arange(output_size)\n",
    "\n",
    "        # Generate the repeat\n",
    "        argument_one = argument_one.repeat(batch_size, output_size)\n",
    "        argument_two = argument_two.repeat(batch_size, input_size)\n",
    "\n",
    "        x_concat = x.repeat(1, output_size).unsqueeze(2).to(x.device)\n",
    "\n",
    "        # Positional Encoding + Concat\n",
    "        argument_one = self.pos_enc(argument_one.detach())\n",
    "        argument_two = self.pos_enc(argument_two.detach())\n",
    "\n",
    "        if extra_out != None:  \n",
    "            argument = torch.concat((argument_one, argument_two, x_concat, extra_out.repeat(1, input_size, 1)), dim=2)\n",
    "        else:\n",
    "            argument = torch.concat((argument_one, argument_two, x_concat), dim=2)\n",
    "        \n",
    "        weights = self.weight_nn(argument.detach()).view(batch_size, input_size, output_size)\n",
    "        x = x.view(batch_size, 1, input_size)\n",
    "        out = torch.bmm(x, weights).squeeze(1)\n",
    "\n",
    "        #* Bias Generation\n",
    "\n",
    "        # Create Bias Argument\n",
    "        argument_one = torch.arange(output_size)\n",
    "        argument_one = self.pos_enc(argument_one.detach()).squeeze(1)\n",
    "        argument_one = argument_one.repeat(batch_size, 1, 1)\n",
    "        argument_two = out.unsqueeze(2)\n",
    "        if extra_out != None:\n",
    "            bias_argument = torch.concat((argument_one, argument_two, extra_out), dim=2)\n",
    "        else:\n",
    "            bias_argument = torch.concat((argument_one, argument_two), dim=2)\n",
    "\n",
    "        # Add bias\n",
    "        bias = self.bias_nn(bias_argument.detach()).squeeze(2)\n",
    "        out += bias\n",
    "\n",
    "        return out\n",
    "\n",
    "    def return_gpu_desc (self):\n",
    "        t = torch.cuda.get_device_properties(0).total_memory\n",
    "        r = torch.cuda.memory_reserved(0)\n",
    "        a = torch.cuda.memory_allocated(0)\n",
    "        f = r-a  # free inside reserved\n",
    "        return f\"Free: {f/1024**2} MB; Allocated: {a/1024**2} MB\"\n",
    "\n",
    "    def forward (self, x, output_size, extra_out=None, chunks=\"all\"):\n",
    "        # Extra Out size: \n",
    "        # first dim is the batch size, second dim is the output space, third dim is the vector added during weight \n",
    "        if extra_out != None:\n",
    "            assert x.size(0) == extra_out.size(0), f\"Batch size of x ({x.size(0)}) is the same as the batch size of extra_out ({extra_out.size(0)})\"\n",
    "\n",
    "        if chunks == \"all\": chunks = output_size\n",
    "        elif chunks == \"none\": chunks = 0\n",
    "\n",
    "        arr = [output_size // chunks for _ in range(chunks)]        \n",
    "        if output_size % chunks > 0: \n",
    "            arr.append(output_size % chunks) \n",
    "\n",
    "        out = torch.tensor([])\n",
    "        output_size = 5\n",
    "\n",
    "        for i in range(len(arr)):\n",
    "            output = self.weight_propagation(x, arr[i], extra_out)\n",
    "            if out.size(0) == 0: \n",
    "                out = output \n",
    "            else:\n",
    "                out = torch.concat((out, output), dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e338e4",
   "metadata": {
    "papermill": {
     "duration": 0.002046,
     "end_time": "2022-10-11T17:11:08.631784",
     "exception": false,
     "start_time": "2022-10-11T17:11:08.629738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAINING CHESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4101f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-11T17:11:08.638182Z",
     "iopub.status.busy": "2022-10-11T17:11:08.637843Z",
     "iopub.status.idle": "2022-10-11T17:11:43.924358Z",
     "shell.execute_reply": "2022-10-11T17:11:43.922952Z"
    },
    "papermill": {
     "duration": 35.291928,
     "end_time": "2022-10-11T17:11:43.925914",
     "exception": true,
     "start_time": "2022-10-11T17:11:08.633986",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "input_database = \"../input/35-million-chess-games/all_with_filtered_anotations_since1998.txt\"\n",
    "output_model = \"./ChessEngine.pth\"\n",
    "\n",
    "# ====================================================== REMOVE HERE ================================================ # \n",
    "input_database = \"./chessDB.txt\"\n",
    "# ====================================================== REMOVE HERE ================================================ # \n",
    "\n",
    "# line cache warmup\n",
    "linecache.getline(input_database, 0) \n",
    "\n",
    "def encode_move (move:chess.Move):\n",
    "    char_to_num = {\n",
    "        \"a\":0,\n",
    "        \"b\":1,\n",
    "        \"c\":2,\n",
    "        \"d\":3,\n",
    "        \"e\":4,\n",
    "        \"f\":5,\n",
    "        \"g\":6,\n",
    "        \"h\":7,\n",
    "    }\n",
    "\n",
    "    uci_str = move.uci()\n",
    "    first_num = char_to_num[uci_str[0]]\n",
    "    second_num = int(uci_str[1])-1\n",
    "    third_num = char_to_num[uci_str[2]]\n",
    "    fourth_num = int(uci_str[3])-1\n",
    "    \n",
    "    return torch.concat((\n",
    "        F.one_hot(torch.tensor([first_num]), num_classes=8),\n",
    "        F.one_hot(torch.tensor([second_num]), num_classes=8),\n",
    "        F.one_hot(torch.tensor([third_num]), num_classes=8),\n",
    "        F.one_hot(torch.tensor([fourth_num]), num_classes=8),\n",
    "    ), dim=1).to(torch.float)\n",
    "\n",
    "def decode_move (x:torch.tensor):\n",
    "    num_to_char = {\n",
    "        0:\"a\",\n",
    "        1:\"b\",\n",
    "        2:\"c\",\n",
    "        3:\"d\",\n",
    "        4:\"e\",\n",
    "        5:\"f\",\n",
    "        6:\"g\",\n",
    "        7:\"h\",\n",
    "    }\n",
    "    x = x.view(-1, 8)\n",
    "    x = torch.argmax(x, dim=1).cpu().tolist()\n",
    "    first_char = num_to_char[x[0]] \n",
    "    second_char = str(x[1]+1) \n",
    "    third_char = num_to_char[x[2]] \n",
    "    fourth_char = str(x[3]+1) \n",
    "    return chess.Move.from_uci(first_char+second_char+third_char+fourth_char)\n",
    "\n",
    "def encode_board (board):\n",
    "    x = 0\n",
    "    y = 0\n",
    "    return_tensor = torch.zeros(1,13,8,8)\n",
    "    for char in board.__str__():\n",
    "        if char == \" \": continue\n",
    "        if char == \"r\":   return_tensor[0][0][x][y] = 1\n",
    "        elif char == \"n\": return_tensor[0][1][x][y] = 1\n",
    "        elif char == \"b\": return_tensor[0][2][x][y] = 1\n",
    "        elif char == \"q\": return_tensor[0][3][x][y] = 1\n",
    "        elif char == \"k\": return_tensor[0][4][x][y] = 1\n",
    "        elif char == \"k\": return_tensor[0][5][x][y] = 1\n",
    "        elif char == \"P\": return_tensor[0][6][x][y] = 1\n",
    "        elif char == \"R\": return_tensor[0][7][x][y] = 1\n",
    "        elif char == \"N\": return_tensor[0][8][x][y] = 1\n",
    "        elif char == \"B\": return_tensor[0][9][x][y] = 1\n",
    "        elif char == \"Q\": return_tensor[0][10][x][y] = 1\n",
    "        elif char == \"K\": return_tensor[0][11][x][y] = 1\n",
    "        if char == \"p\":   return_tensor[0][12][x][y] = 1\n",
    "\n",
    "        x += 1\n",
    "        if char == \"\\n\": \n",
    "            y += 1\n",
    "            x = 0\n",
    "    return return_tensor\n",
    "\n",
    "class ChessClassificationDatabase(torch.utils.data.Dataset):\n",
    "    def __init__(self, num_games):\n",
    "        assert num_games > 0\n",
    "        self.x = torch.tensor([]) \n",
    "        self.y = torch.tensor([])\n",
    "        self.possible_moves = []\n",
    "\n",
    "        len_lines = 3561469\n",
    "        for i in range(num_games):\n",
    "            try:\n",
    "                line = linecache.getline(input_database, randint(0, len_lines)+6) \n",
    "                board = chess.Board()\n",
    "\n",
    "                line = line.split(\"###\")[1].strip()\n",
    "                moves = line.split(\" \")\n",
    "\n",
    "                for move in moves:\n",
    "                    move = move.split(\".\")[1]\n",
    "                    tensor_board = encode_board(board)\n",
    "                    actual_move = board.parse_san(move)\n",
    "                    possible_move = torch.tensor([])\n",
    "\n",
    "                    # Encode possible moves\n",
    "                    legal_moves = board.legal_moves\n",
    "                    for move in legal_moves:\n",
    "                        move_enc = encode_move(move)\n",
    "                        if possible_move.size(0) == 0: possible_move = move_enc\n",
    "                        else: possible_move = torch.concat((possible_move, move_enc), dim=0)\n",
    "\n",
    "                    # Append to variables\n",
    "                    self.possible_moves.append(possible_move)\n",
    "                    y_enc = list(legal_moves).index(actual_move)\n",
    "                    y_enc = torch.tensor([[y_enc]])\n",
    "                    if self.x.size(0) == 0:\n",
    "                        self.x = tensor_board\n",
    "                        self.y = y_enc \n",
    "                    else:\n",
    "                        self.x = torch.vstack((self.x, tensor_board))\n",
    "                        self.y = torch.vstack((self.y, y_enc))\n",
    "\n",
    "                    board.push(actual_move)\n",
    "            except:\n",
    "                continue\n",
    "        self.x = self.x.to(device)\n",
    "        self.y = self.y.to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.size(0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index].detach(), self.y[index].detach(), self.possible_moves[index].to(device).detach()\n",
    "\n",
    "class PolicyNeuralNetwork (nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.neuralNet = nn.Sequential(\n",
    "            nn.Conv2d(13, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(128),\n",
    "            nn.Tanh(),\n",
    "            nn.LazyLinear(64),\n",
    "        )\n",
    "\n",
    "        d_model = 16\n",
    "\n",
    "        weight_model = nn.Sequential(\n",
    "            nn.Linear(65, 16),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(16, 1),\n",
    "        ) \n",
    "\n",
    "        bias_model = nn.Sequential(\n",
    "            nn.Linear(49, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 1),\n",
    "        )\n",
    "\n",
    "        self.model = VNNBlock(d_model, weight_model, bias_model)\n",
    "\n",
    "    def forward (self, x, possible_moves):\n",
    "        x = self.neuralNet(x)\n",
    "        return self.model(x, possible_moves.size(1), possible_moves)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bee6d8",
   "metadata": {},
   "source": [
    "## MAIN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d02eb30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eshaa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "  0%|          | 0/10000 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 2. Expected size 64 but got size 1280 for tensor number 3 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eshaa\\OneDrive\\Desktop\\Coding\\ResearchProject\\ChessBenchmark\\vnn-chess-dataset.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m y \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m possible_moves \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m][\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m out \u001b[39m=\u001b[39m model(x, possible_moves) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m data_loss \u001b[39m=\u001b[39m criterion(out, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m data_loss \u001b[39m=\u001b[39m data_loss\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\eshaa\\OneDrive\\Desktop\\Coding\\ResearchProject\\ChessBenchmark\\vnn-chess-dataset.ipynb Cell 7\u001b[0m in \u001b[0;36mPolicyNeuralNetwork.forward\u001b[1;34m(self, x, possible_moves)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m (\u001b[39mself\u001b[39m, x, possible_moves):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneuralNet(x)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x, possible_moves\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m), possible_moves)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\eshaa\\OneDrive\\Desktop\\Coding\\ResearchProject\\ChessBenchmark\\vnn-chess-dataset.ipynb Cell 7\u001b[0m in \u001b[0;36mVNNBlock.forward\u001b[1;34m(self, x, output_size, extra_out, chunks)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m output_size \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(arr)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_propagation(x, arr[i], extra_out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m         out \u001b[39m=\u001b[39m output \n",
      "\u001b[1;32mc:\\Users\\eshaa\\OneDrive\\Desktop\\Coding\\ResearchProject\\ChessBenchmark\\vnn-chess-dataset.ipynb Cell 7\u001b[0m in \u001b[0;36mVNNBlock.weight_propagation\u001b[1;34m(self, x, output_size, extra_out)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m argument_two \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc(argument_two\u001b[39m.\u001b[39mdetach())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mif\u001b[39;00m extra_out \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:  \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     argument \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mconcat((argument_one, argument_two, x_concat, extra_out\u001b[39m.\u001b[39;49mrepeat(\u001b[39m1\u001b[39;49m, input_size, \u001b[39m1\u001b[39;49m)), dim\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eshaa/OneDrive/Desktop/Coding/ResearchProject/ChessBenchmark/vnn-chess-dataset.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     argument \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat((argument_one, argument_two, x_concat), dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 2. Expected size 64 but got size 1280 for tensor number 3 in the list."
     ]
    }
   ],
   "source": [
    "# Optimizer and training parameters\n",
    "batch_size = 16\n",
    "validation_size = 64\n",
    "num_games_per_itr = 4\n",
    "lr = 0.001\n",
    "itr = 10_000\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model = PolicyNeuralNetwork().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training Loop\n",
    "progress_bar = trange(itr)\n",
    "itr = 0\n",
    "mag = 1\n",
    "for i in progress_bar:\n",
    "    # Get data\n",
    "    dataset = ChessClassificationDatabase(num_games=num_games_per_itr),\n",
    "\n",
    "    # Train on that data\n",
    "    opt.zero_grad()\n",
    "    losses = torch.tensor([])\n",
    "    for data in dataset:\n",
    "        x = data[0][0].unsqueeze(0)\n",
    "        y = data[0][1]\n",
    "        possible_moves = data[0][2].unsqueeze(0)\n",
    "        out = model(x, possible_moves) \n",
    "        data_loss = criterion(out, y)\n",
    "        data_loss = data_loss.unsqueeze(0)\n",
    "        if losses.size(0) == 0: losses = data_loss\n",
    "        else: losses = torch.concat((losses, data_loss), 0)\n",
    "    loss = torch.mean(losses)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    progress_bar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    if i % 100 == 0 and i != 0:  \n",
    "        # Save Model\n",
    "        torch.save(nn, output_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 59.304856,
   "end_time": "2022-10-11T17:11:46.849024",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-11T17:10:47.544168",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
